{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word2number import w2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv containing Dengue articles to a dataframe\n",
    "df = pd.read_csv('TestDengueContent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mysql.connector import MySQLConnection, Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "  'user': 'root',\n",
    "  'password': '',\n",
    "  'host': '127.0.0.1',\n",
    "  'database': 'dengue_sri_lanka',\n",
    "  'raise_on_warnings': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "try:\n",
    "#     mySQLconnection = mysql.connector.connect(host='localhost',\n",
    "#                              database='dengue_sri_lanka',\n",
    "#                              user='root',\n",
    "#                              password='')\n",
    "    conn = MySQLConnection(**config)\n",
    "#     sql_select_Query = \"select * from news_articles\"\n",
    "    select_new_articles = \"select * from news_articles where isDataExtracted=0\"\n",
    "\n",
    "    cursor = conn .cursor()\n",
    "    cursor.execute(select_new_articles)\n",
    "    records = cursor.fetchall()\n",
    "#     \n",
    "    print(\"Total number of rows in news_articles is - \", cursor.rowcount)\n",
    "    print (\"Printing each row's column values i.e.  developer record\")\n",
    "    for row in records:\n",
    "#        print(\"Id = \", row[0], )\n",
    "#        print(\"Name = \", row[1])\n",
    "#        print(\"JoiningDate  = \", row[2])\n",
    "        print(\"Content  = \", row[3], \"\\n\")\n",
    "#     \n",
    "    cursor.close()\n",
    "   \n",
    "except Error as e :\n",
    "    print (\"Error while connecting to MySQL\", e)\n",
    "finally:\n",
    "    #closing database connection.\n",
    "    if(conn .is_connected()):\n",
    "        conn.close()\n",
    "        print(\"MySQL connection is closed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "df = df.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops duplicate entries\n",
    "df.drop_duplicates(subset=None, keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_for_publication_date = re.compile(r\"\"\"(?:\\d{4}-\\d{2}-\\d{2})|(?:\\d{1,2}\\s*(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|April|May|June|July|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\\s*\\d{4})\"\"\",re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex for publication date ####-##-##\n",
    "regex_for_publication_date1 = r\"\\d{4}-\\d{2}-\\d{2}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_for_numbers = re.compile(r'\\d+(?:(?:,|\\s|(?:,\\s)|(?:\\s,))\\d+)*');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_for_cases = re.compile(r'(\\d+(?:(?:,|\\s|(?:,\\s)|(?:\\s,))\\d{1,3}){0,1})\\s*(?:dengue\\scases|dengue\\sfever\\scases|cases|suspected\\sdengue\\scases|suspected\\scases|suspected\\sdengue\\sfever\\scases|patients|dengue\\spatients|from)', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a number following 'cases' or 'suspected dengue cases' or 'suspected cases'\n",
    "regex_for_cases2 = re.compile(r'(\\d+(?:(?:,|\\s|(?:,\\s)|(?:\\s,))\\d+)*)\\s*(?:dengue\\scases|dengue\\sfever\\scases|cases|suspected\\sdengue\\scases|suspected\\scases|suspected\\sdengue\\sfever\\scases)', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_for_cases1 = re.compile(r'\\d+(?:(?:,|\\s|(?:,\\s)|(?:\\s,))\\d+)*\\s*(?:dengue\\scases|dengue\\sfever\\scases|cases|suspected\\sdengue\\scases|suspected\\scases|suspected\\sdengue\\sfever\\scases)', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_for_deaths = re.compile(r\"\"\"((?:\\d+)|(?:[^\\S]\\d{1,3}(?:(?:,|\\s|(?:,\\s)|(?:\\s,))\\d+)+)|\n",
    "(?:one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|\n",
    "(?:(?:(?:twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety)\\s*)(?:one|two|three|four|five|six|seven|eight|nine)?)))\n",
    "\\s*\n",
    "(?:deaths|death|dead\\b|(?:people\\s*|patients\\s*)?(?:have\\s*|had\\s*)?(?:died|dead\\b)|dengue(?:\\s|-)related\\sdeath)\n",
    "\"\"\", re.VERBOSE | re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex for deaths or patients(TODO move patients to no.of cases)\n",
    "regex_for_deaths1 = re.compile(r\"\"\"\n",
    "(?:(?:\\d+(?:(?:,|\\s|(?:,\\s)|(?:\\s,))\\d+)*)|\n",
    "(?:one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|\n",
    "(?:(?:(?:twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety)\\s*)(?:one|two|three|four|five|six|seven|eight|nine)?)))\n",
    "\\s*\n",
    "(?:deaths|death|dead\\b|(?:people\\s*|patients\\s*)?(?:have\\s*|had\\s*)?(?:died|dead\\b)|patients|dengue\\srelated\\sdeath)\n",
    "\n",
    "\"\"\", re.VERBOSE | re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex to extract sentences having no. of cases/deaths\n",
    "# TODO handle for \"i.e\" \n",
    "regex_for_sentences = re.compile(r\"[^.]*?(?:\\d+(?:(?:,|\\s|(?:,\\s)|(?:\\s,))\\d+)*\\s*(?:dengue\\scases|dengue\\sfever\\scases|cases|suspected\\sdengue\\scases|suspected\\scases|suspected\\sdengue\\sfever\\scases)|(?:(?:(?:\\d+(?:(?:,|\\s|(?:,\\s)|(?:\\s,))\\d+)*)|(?:one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|(?:(?:(?:twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety)\\s*)(?:one|two|three|four|five|six|seven|eight|nine)?)))\\s*(?:deaths|death|dead\\b|(?:people\\s*|patients\\s*)?(?:have\\s*|had\\s*)?(?:died|dead\\b)|patients|dengue\\srelated\\sdeath)))[^.]*\\.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex for dates\n",
    "regex_for_dates1 = re.compile(r\"\"\"(?:\\d{4}(?:\\.|/|-)\\d{1,2}(?:\\.|/|-)\\d{1,2})|                                                                       # dates with format xxxx.xx.xx or xxxx/xx/xx or xxxx-xx-xx (month and date: 1 or 2 digits)\n",
    "(?:\\d{1,2}(?:\\.|/|-)\\d{1,2}(?:\\.|/|-)\\d{2,4})|                                                                                                      # dates with format xx.xx.xx where . or / or - used as the seperator, 1 or 2 digits for date or month, 2 or 4 digits for year\n",
    "(?:(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|April|May|June|July|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\\s*\\d{0,2})     # dates with format: month xx (date with 0-2 digits)\n",
    "\"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex_for_years 20xx\n",
    "regex_for_years = re.compile(r\"\"\"\\b20(?:\\d{2}){1}\\b|this\\syear\"\"\", re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex for months\n",
    "regex_for_months = re.compile(r'Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|April|May|June|July|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex for \"so far\"\n",
    "regex_for_so_far = re.compile(r'so\\sfar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex for districts\n",
    "regex_for_districts = re.compile(r'Jaffna|Kilinochchi|Mannar|Mullaitivu|Vavuniya|Puttalam|Kurunegala|Gampaha|Colombo|Kalutara|Anuradhapura|Polonnaruwa|Matale|Kandy|Nuwara\\sEliya|Kegalle|Ratnapura|Trincomalee|Trinco|Batticaloa|Ampara|Badulla|Monaragala|Hambantota|Matara|Galle', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex for provinces\n",
    "regex_for_provinces = re.compile(r'Western|Central|Eastern|North\\sCentral|Northern|North\\sWestern|Sabaragamuwa|Southern|Uva')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex for other places/locations\n",
    "regex_for_places = re.compile(r'Sri Lanka|island|country|countrywide|Meethotamulla|Negombo|Ratmalana|Dangolla|Elpitiya|Beliatte|Hatton|Marakolliya|Gampola|Kalubowila')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2018-05-09', '07 Feb 2019']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_published_date(\"2018-05-09 09:26:47 54 Thu, 07 Feb 2019 16:08:56 +0000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(text):\n",
    "    return regex_for_sentences.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_for_dates = re.compile(r\"\"\"(?:\\d{1,2}\\s*(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|April|May|June|July|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\\s*\\d{4})\"\"\",re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month_in_number(month):\n",
    "    m = {\n",
    "        'jan': 1,\n",
    "        'feb': 2,\n",
    "        'mar': 3,\n",
    "        'apr':4,\n",
    "        'may':5,\n",
    "        'jun':6,\n",
    "        'jul':7,\n",
    "        'aug':8,\n",
    "        'sep':9,\n",
    "        'oct':10,\n",
    "        'nov':11,\n",
    "        'dec':12\n",
    "        }\n",
    "    s = month.strip()[:3].lower()\n",
    "\n",
    "    try:\n",
    "        out = m[s]\n",
    "        return out\n",
    "    except:\n",
    "        raise ValueError('Not a month')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_published_date(text):\n",
    "    dates = regex_for_publication_date.findall(text)\n",
    "#     print(dates)\n",
    "    for index,date in enumerate(dates):\n",
    "        if(regex_for_dates.match(date)):\n",
    "            day = re.search('\\d{1,2}', date).group()\n",
    "#             print(day)\n",
    "#             print(re.search('\\D{3,9}', date).group())\n",
    "            month = get_month_in_number(re.search('\\D{3,9}', date).group())\n",
    "#             print(month)\n",
    "            year = re.search('\\d{4}', date).group()\n",
    "#             print(year)\n",
    "            date = year + \"-\" + str(month) + \"-\" + day\n",
    "            dates[index] = date\n",
    "    \n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numbers(text):\n",
    "    return regex_for_numbers.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cases(text):\n",
    "    cases = regex_for_cases.findall(text)\n",
    "    for index,case in enumerate(cases):\n",
    "        case = case.replace(\" \",\"\")\n",
    "        case = case.replace(\",\",\"\")\n",
    "        case = int(case)   \n",
    "        cases[index] = case\n",
    "    return cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cases1(text):\n",
    "    return regex_for_cases1.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[345, 132999]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cases(\"345 cases and s 132, 999 cases reported yesterday, more than fifty deaths 12 deaths. Twenty six people have died\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_for_digits = re.compile(r'(?:(?:\\s)*\\d+(?:(?:\\s)\\d+)*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deaths(text):\n",
    "    deaths = regex_for_deaths.findall(text)\n",
    "    print(deaths)\n",
    "    for index,death in enumerate(deaths):\n",
    "#         print(regex_for_digits.match(death))\n",
    "        if(regex_for_digits.match(death)):\n",
    "            death = death.replace(\" \",\"\")\n",
    "            death = death.replace(\",\",\"\")\n",
    "#             print(death)\n",
    "        death = w2n.word_to_num(death)   \n",
    "        \n",
    "        deaths[index] = death\n",
    "    return deaths        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['2018']\n",
    "def get_years(text,text_date):\n",
    "    years = regex_for_years.findall(text)    \n",
    "    for index,year in enumerate(years):\n",
    "        if(year.lower() == \"this year\"):\n",
    "            pub_date = get_published_date(text_date)\n",
    "            year = re.search('\\d{4}',pub_date).group()\n",
    "            years[index] = year\n",
    "    return years\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_years1(text):\n",
    "    return regex_for_years.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_months(text):\n",
    "    return regex_for_months.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(text):\n",
    "    return regex_for_dates.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_so_far(text):\n",
    "    return regex_for_so_far.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_provinces(text):\n",
    "    return regex_for_provinces.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_districts(text):\n",
    "    return regex_for_districts.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_places(text):\n",
    "    return regex_for_places.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations=[\"Meethotamulla\",\"Colombo\", \"kandy\",\"Anuradhapura\",\"Galle\",\"Matara\",\"Ratmalana\",\"Dangolla\",\"Badulla\",\"Elpitiya\",\"Beliatte\",\"Hatton\",\"Marakolliya\",\"Gampola\",\"Kalubowila\",\"Puttalam\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_for_sentences = re.compile(r\"[^.]*?(?:\\d+(?:(?:,|\\s|(?:,\\s)|(?:\\s,))\\d+)*\\s*(?:dengue|dengue\\scases|dengue\\sfever\\scases|cases|suspected\\sdengue\\scases|suspected\\scases|suspected\\sdengue\\sfever\\scases)|(?:(?:(?:\\d+(?:(?:,|\\s|(?:,\\s)|(?:\\s,))\\d+)*)|(?:one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|(?:(?:(?:twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety)\\s*)(?:one|two|three|four|five|six|seven|eight|nine)?)))\\s*(?:deaths|death|dead\\b|(?:people\\s*|patients\\s*)?(?:have\\s*|had\\s*)?(?:died|dead\\b)|patients|dengue\\srelated\\sdeath)))[^.]*\\.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_for_sentences1 = re.compile(r\"[^.]*?(?:\\d+(?:(?:,|\\s|(?:,\\s)|(?:\\s,))\\d+)*\\s*(?:dengue|cases|suspected\\sdengue\\scases|suspected\\scases)|(?:(?:(?:\\d+(?:(?:,|\\s|(?:,\\s)|(?:\\s,))\\d+)*)|(?:one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|(?:(?:(?:twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety)\\s*)(?:one|two|three|four|five|six|seven|eight|nine)?)))\\s*(?:deaths|death|dead(?:people\\s*|patients\\s*)?(?:have\\s*|had\\s*)?(?:died|dead)|patients)))[^.]*\\.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019-1-17']\n",
      "['2019-1-17']\n",
      "['2019-1-17']\n",
      "['2019-1-17']\n",
      "['2019-1-17']\n",
      "['2019-1-17']\n",
      "['2019-1-17']\n",
      "['2019-1-17']\n",
      "['2019-1-17']\n",
      "['2019-1-17']\n",
      "['2019-1-17']\n",
      "['2019-1-17']\n",
      "['2019-1-17']\n",
      "['2019-1-17']\n",
      "['2019-1-16']\n",
      "['2019-1-16']\n",
      "['2019-1-16']\n",
      "['2019-1-16']\n",
      "['2019-1-16']\n",
      "['2019-1-16']\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "#     print(regex_for_sentences.findall(row['Article_content']))\n",
    "#     print(\"*\")\n",
    "#     for sentence in regex_for_sentences.findall(row['Article_content']):\n",
    "#         print(regex_for_sentences.findall(row['Article_content']))\n",
    "#         print(get_deaths1(sentence))\n",
    "    print(get_published_date(row['Date']))\n",
    "#         print(get_years(sentence,row['Date']))\n",
    "#         print(get_years1(sentence))\n",
    "#     print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles=[]\n",
    "for index, row in df.iterrows():\n",
    "    print(\"Index: \"+str(index))\n",
    "#     print(\"Publication date: \"+get_published_date(row['Date']))\n",
    "    sentences = get_sentences(row['Article_content'])\n",
    "#     print(sentences)\n",
    "    for sentence in sentences:\n",
    "        print(sentence)\n",
    "#         get_data(sentence)\n",
    "        \n",
    "        articles.append({\n",
    "                'Index':str(index),\n",
    "                'Publication_date':get_published_date(row['Date']),\n",
    "                'Sentence':sentence.encode(\"utf-8\"),\n",
    "                'Numbers':get_cases1(sentence),\n",
    "                'Cases':get_cases(sentence),\n",
    "                'Deaths':get_deaths(sentence),\n",
    "                'Years':get_years(sentence),\n",
    "                'Months':get_months(sentence),\n",
    "                'Dates': get_dates(sentence),\n",
    "                'Time_duration':get_so_far(sentence),\n",
    "                'Provinces':get_provinces(sentence),\n",
    "                'Districts':get_districts(sentence),\n",
    "                'Places':get_places(sentence),\n",
    "            })\n",
    "        \n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles=[]\n",
    "for row in records:\n",
    "    sentences = get_sentences(row[3])\n",
    "    for sentence in sentences:\n",
    "        print(sentence)\n",
    "        \n",
    "        articles.append({\n",
    "                'Index':str(index),\n",
    "                'Publication_date':get_published_date(row[1]),\n",
    "                'Sentence':sentence.encode(\"utf-8\"),\n",
    "                'Numbers':get_cases1(sentence),\n",
    "                'Cases':get_cases(sentence),\n",
    "                'Deaths':get_deaths(sentence),\n",
    "                'Years':get_years(sentence),\n",
    "                'Months':get_months(sentence),\n",
    "                'Dates': get_dates(sentence),\n",
    "                'Time_duration':get_so_far(sentence),\n",
    "                'Provinces':get_provinces(sentence),\n",
    "                'Districts':get_districts(sentence),\n",
    "                'Places':get_places(sentence),\n",
    "            })\n",
    "        \n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles=[]\n",
    "conn = MySQLConnection(**config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for row in records:\n",
    "#     print(row[3].decode(\"utf-8\"))\n",
    "    sentences = get_sentences(row[3].decode(\"utf-8\"))\n",
    "#     print(sentences)\n",
    "    for sentence in sentences:\n",
    "        print(sentence)\n",
    "        \n",
    "        publication_date = get_published_date(row[1])\n",
    "#         sentence = sentence.encode(\"utf-8\")\n",
    "#         numbers = get_cases1(sentence)\n",
    "        cases = get_cases(sentence)\n",
    "        deaths = get_deaths(sentence)\n",
    "        year = get_years(sentence)\n",
    "        month = get_months(sentence)\n",
    "#         dates = get_dates(sentence)\n",
    "        time_duration = get_so_far(sentence)\n",
    "        province = get_provinces(sentence)\n",
    "        district = get_districts(sentence)\n",
    "        countrywide = get_places(sentence)\n",
    "        \n",
    "        query = \"INSERT IGNORE INTO regex_output(publication_date, cases, deaths, year, month, time_duration, province, countrywide, article_id, district) \" \\\n",
    "            \"VALUES(publication_date, cases, deaths, year, month, time_duration, province, countrywide, 1, district)\"\n",
    "        \n",
    "        try:\n",
    "#         db_config = read_db_config()\n",
    " \n",
    "            cursor.execute(query)\n",
    "            conn.commit()\n",
    "            \n",
    "        except Error as error:\n",
    "            print(error)\n",
    "        \n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles=[]\n",
    "conn = MySQLConnection(**config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# for row in records:\n",
    "#     print(row[3].decode(\"utf-8\"))\n",
    "#     sentences = get_sentences(row[3].decode(\"utf-8\"))\n",
    "#     print(sentences)\n",
    "#     for sentence in sentences:\n",
    "#         print(sentence)\n",
    "        \n",
    "#         publication_date = get_published_date(row[1])\n",
    "# #         sentence = sentence.encode(\"utf-8\")\n",
    "# #         numbers = get_cases1(sentence)\n",
    "#         cases = get_cases(sentence)\n",
    "#         deaths = get_deaths(sentence)\n",
    "#         year = get_years(sentence)\n",
    "#         month = get_months(sentence)\n",
    "# #         dates = get_dates(sentence)\n",
    "#         time_duration = get_so_far(sentence)\n",
    "#         province = get_provinces(sentence)\n",
    "#         district = get_districts(sentence)\n",
    "#         countrywide = get_places(sentence)\n",
    "        \n",
    "query = \"INSERT IGNORE INTO regex_output(publication_date, cases, deaths, year, month, time_duration, province, countrywide, article_id, district) \" \\\n",
    "            \"VALUES('01/01/2018', 23455, 234, ['2019'], 'month', 'time', 'province', 'countrywide', 1, 'district')\"\n",
    "        \n",
    "try:\n",
    "#         db_config = read_db_config()\n",
    " \n",
    "    cursor.execute(query)\n",
    "    conn.commit()\n",
    "            \n",
    "except Error as error:\n",
    "    print(error)\n",
    "        \n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO IMPORTANT: set the isDataExtracted column of each row to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data in the 'article' list to a csv\n",
    "with open('Regex_output_test1.csv',mode='w') as csv_file:\n",
    "    fieldnames=['Index','Publication_date','Sentence','Numbers','Cases','Deaths','Years','Months','Dates','Time_duration','Provinces','Districts','Places']\n",
    "    writer=csv.DictWriter(csv_file,fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for article in articles:\n",
    "        writer.writerow({'Index':article['Index'],'Publication_date':article['Publication_date'],'Sentence':article['Sentence'],'Numbers':article['Numbers'],'Cases':article['Cases'],'Deaths':article['Deaths'],'Years':article['Years'],'Months':article['Months'],'Dates':article['Dates'],'Time_duration':article['Time_duration'],'Provinces':article['Provinces'],'Districts':article['Districts'],'Places':article['Places']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# locations=[\"Meethotamulla\",\"Colombo\", \"kandy\",\"Anuradhapura\",\"Galle\",\"Matara\",\"Ratmalana\",\"Dangolla\",\"Badulla\",\"Elpitiya\",\"Beliatte\",\"Hatton\",\"Marakolliya\",\"Gampola\",\"Kalubowila\",\"Puttalam\",]\n",
    "\n",
    "# import pandas as pd\n",
    "# import csv\n",
    "\n",
    "# df = pd.read_csv('TestDengueContent.csv')\n",
    "# df = df.fillna(\"\")\n",
    "# print(df.shape)\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#         for line in (row):\n",
    "#             i=0\n",
    "#             while i<len(locations):\n",
    "#                 if locations[i] in line:\n",
    "#                     print(locations[i])\n",
    "#                 i+=1\n",
    "\n",
    "# # for index, row in df.iterrows():\n",
    "# #         for line in (row):\n",
    "# #             for location in locations:\n",
    "# #                 if location in line:\n",
    "# #                     print(location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"Contamination of the food chain and waterways continue to pose serious public health risks in many countries including Sri Lanka.\t\tMoreover, the spread of unhealthy food habits, often propagated by big multinationals, has become a public health menace not just in developing countries but in the most developed parts of the world as well, i.e. America, Europe, Australasia and elsewhere.\t\tRecognizing the wider background to growing public health risks in different parts of the world, the WHO commissioned and publishedï¿½ several years ago a well-articulated report on Social Determinants of Health (SDH) . \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sent_tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word2number import w2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "print(w2n.word_to_num('Twenty six'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(calendar.month_abbr).index('Jan')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
